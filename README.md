# ğŸ™ï¸ Speaker Diarization Enhancement Using Denoising DL-Model
**ë”¥ëŸ¬ë‹ ê¸°ë°˜ ì¡ìŒ ì œê±° ëª¨ë¸ì„ í™œìš©í•œ í™”ì ë¶„ë¦¬ ì •í™•ë„ í–¥ìƒ ì‹œìŠ¤í…œ**

---

## ğŸ§© í”„ë¡œì íŠ¸ í•œ ì¤„ ìš”ì•½
> **ë”¥ëŸ¬ë‹ ê¸°ë°˜ ì¡ìŒ ì œê±°(denoising) + ë“€ì–¼ ì†ŒìŠ¤ VAD í•˜ì´ë¸Œë¦¬ë“œ ëª¨ë¸ì„ í†µí•´ ì‹¤ì œ êµì‹¤/íšŒì˜ í™˜ê²½ì—ì„œë„ DERì„ ë‚®ì¶˜ ê³ ì •í™•ë„ í™”ì ë¶„ë¦¬ ì‹œìŠ¤í…œ**

---

## ğŸ”— ê¸°ì¡´ í”„ë¡œì íŠ¸ ë° ì°¸ê³  ë§í¬
- **ê¸°ì¡´ í”„ë¡œì íŠ¸ GitHub:** [nemo-multistage-classroom-diarization](https://github.com/EduNLP/nemo-multistage-classroom-diarization.git)
- **ì°¸ê³  ë…¼ë¬¸:** [EDM 2025 - Multistage Classroom Diarization](https://educationaldatamining.org/edm2025/proceedings/2025.EDM.short-papers.199/)  

---

## ğŸ“˜ Overview  

### ğŸ¯ ë¬¸ì œì   
ê¸°ì¡´ì˜ í™”ì ë¶„ë¦¬ ì‹œìŠ¤í…œì€ **ì‹œë„ëŸ½ê³  ë‹¤ì–‘í•œ ì†ŒìŒì´ ì¡´ì¬í•˜ëŠ” êµì‹¤Â·íšŒì˜ í™˜ê²½**ì—ì„œ ì„±ëŠ¥ì´ ê¸‰ê²©íˆ ì €í•˜ë¨.  
- ì „í†µì ì¸ ì˜¤ë””ì˜¤ ì¡ìŒ ì œê±° ì•Œê³ ë¦¬ì¦˜(`sainburg noisereduce`)ì€ **ìŠ¤í™íŠ¸ë¡œê·¸ë¨ ê°ì‚°** ê¸°ë²•ìœ¼ë¡œ ë‹¨ìˆœí•œ ë…¸ì´ì¦ˆ ì–µì œëŠ” ê°€ëŠ¥í•˜ë‚˜,  
  - ë‚®ì€ ë³¼ë¥¨ì˜ ë°œí™”ë¥¼ ì†Œê±°í•˜ê±°ë‚˜  
  - í™”ìì˜ ìŒìƒ‰(formant)ì„ ì™œê³¡í•˜ëŠ” ë¬¸ì œê°€ ì¡´ì¬í•¨.  

### ğŸ’¡ í•´ê²°ë°©ì•ˆ  
ë³¸ í”„ë¡œì íŠ¸ëŠ” ë‹¤ìŒì„ ê²°í•©í•œ **ë‹¤ë‹¨ê³„ í•˜ì´ë¸Œë¦¬ë“œ íŒŒì´í”„ë¼ì¸**ì„ ì œì•ˆí•¨.  
1. **ë”¥ëŸ¬ë‹ ê¸°ë°˜ Speech Enhancement (DCCRN, DeepFilterNet ë“±)**  
   - ì¡ìŒ ì–µì œ + í™”ì ìŒìƒ‰ ë³´ì¡´  
2. **ë“€ì–¼ ì†ŒìŠ¤ VAD (wav2vec2 + Whisper)**  
   - ì†ŒìŒ í™˜ê²½ì—ì„œë„ ëª…í™•í•œ ë°œí™” êµ¬ê°„ ê²€ì¶œ  
3. **NeMo ê¸°ë°˜ Speaker Embedding + Clustering + Labeling**  
   - ê¹¨ë—í•œ ì˜¤ë””ì˜¤ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í™”ì ì„ë² ë”© í’ˆì§ˆ í–¥ìƒ  
   - DER(Diarization Error Rate) ê°ì†Œ  

---

## ğŸ§  System Pipeline  

```
Noisy Audio
     â†“
[Phase 1] Deep Learning Speech Enhancement
     â†“
[Phase 2] Dual-Source VAD (wav2vec2 + Whisper)
     â†“
[Phase 3] VAD Fusion & Segmentation
     â†“
[Phase 4] Speaker Embedding & Clustering (NeMo)
     â†“
[Phase 5] Speaker Labeling
     â†“
Enhanced & Tagged Audio Output
```

---

## ğŸ’» Demo  

### ğŸ§ Input Example
```
classbank_audio_data/audio/2.wav
```

### âš™ï¸ Output Example
```
diarization_output/2_denoised_diarized.rttm
vad_outs.json
```

| File | Description |
|------|--------------|
| `.wav` | ì…ë ¥ ì˜¤ë””ì˜¤ íŒŒì¼ |
| `.json` | VAD ê²°ê³¼ (ìŒì„± êµ¬ê°„ ì •ë³´) |
| `.rttm` | í™”ì ë¶„ë¦¬ ê²°ê³¼ (who spoke when) |

---

## ğŸ“ˆ Result & Performance  

### ğŸ§® í‰ê°€ ì§€í‘œ (DER)
```
DER = (FA + MISS + CER) / Duration
```
| Metric | ì˜ë¯¸ |
|---------|------|
| FA (False Alarm) | ë°œí™” ì—†ìŒ â†’ ìˆìŒìœ¼ë¡œ ì˜¤íƒ |
| MISS | ì‹¤ì œ ë°œí™” â†’ ë¯¸íƒì§€ |
| CER (Confusion Error Rate) | ë°œí™”ëŠ” íƒì§€í–ˆìœ¼ë‚˜ í™”ì í• ë‹¹ ì˜¤ë¥˜ |

### ğŸ“Š ê²°ê³¼
- ê¸°ì¡´ Sainburg ì•Œê³ ë¦¬ì¦˜ ëŒ€ë¹„ DER ê°ì†Œ
- Whisper + wav2vec2 ë³‘í•© ì‹œ ì•ˆì •ì  ë°œí™” ê²€ì¶œ í–¥ìƒ
- ì €ì§„í­ ë°œí™” ì¸ì‹ë¥  ìƒìŠ¹ ë° ì¡ìŒ í™˜ê²½ ê°•ê±´ì„± í–¥ìƒ  

---

## âš™ï¸ Installation  

```bash
# 1. Clone repository
git clone https://github.com/jth1097/Deep-learning-preproceng-pipelinssie-speaker-diarization-system.git
cd Deep-learning-preproceng-pipelinssie-speaker-diarization-system

# 2. Create and activate virtual environment
python3 -m venv .venv
source .venv/bin/activate     # (Windows: .venv\Scripts\activate)

# 3. Install dependencies
pip install -r requirements.txt

# 4. (Optional) Install NeMo and PyTorch
pip install nemo_toolkit[asr]
```

---

## ğŸš€ Usage  

```bash
# ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
bash run.sh

# ë˜ëŠ” Python ìŠ¤í¬ë¦½íŠ¸ ì§ì ‘ ì‹¤í–‰
python run_diarization.py --input ./classbank_audio_data/audio/2.wav --output ./diarization_output
```

- `manifests/test.json` : ì˜¤ë””ì˜¤ ê²½ë¡œ ë° ë©”íƒ€ë°ì´í„° ëª©ë¡  
- `vad_outs.json` : VAD ê²°ê³¼ ì¤‘ê°„ ì‚°ì¶œë¬¼  
- `diarization_output` : ìµœì¢… í™”ì ë¶„ë¦¬ ê²°ê³¼ ì €ì¥ í´ë”  

---

## âš ï¸ Common Issues & Solutions  

| ë¬¸ì œ | ì›ì¸ | í•´ê²° ë°©ë²• |
|------|------|------------|
| `PySoundFile failed` | libsndfile ë¯¸ì„¤ì¹˜ | `sudo apt install libsndfile1` |
| CUDA ì˜¤ë¥˜ (`device not found`) | GPU í™˜ê²½ ë¯¸ì„¤ì • | CUDA 11.8 + cuDNN 8.6 ë²„ì „ í™•ì¸ |
| VAD ê²°ê³¼ ì—†ìŒ | ì…ë ¥ íŒŒì¼ í˜•ì‹ ë¶ˆì¼ì¹˜ | 16kHz mono PCM í˜•ì‹ìœ¼ë¡œ ë³€í™˜ |
| 0 bytes output | ffmpeg ë³€í™˜ ì‹¤íŒ¨ | `ffmpeg -i input.wav -ar 16000 -ac 1 output.wav` ë¡œ ì¬ìƒì„± |
| ë©”ëª¨ë¦¬ ë¶€ì¡± | ë”¥ëŸ¬ë‹ ëª¨ë¸ ë©”ëª¨ë¦¬ ì´ˆê³¼ | `--batch_size` ê°ì†Œ ë˜ëŠ” GPU ë©”ëª¨ë¦¬ ì¦ê°€ í•„ìš” |

---

## ğŸ§© Future Work  

- ë”¥ëŸ¬ë‹ ì „ì²˜ë¦¬ ëª¨ë¸ **Fine-tuning** (ì¡ìŒ í¬í•¨ vs ì œê±° ë°ì´í„° ë³‘í•© í•™ìŠµ)  
- ë¼ë²¨ë§ + Audio-to-Text ì—°ë™ìœ¼ë¡œ **ì‹œê°ì  í™”ì êµ¬ë¶„ ìë£Œ ìƒì„±**  
- ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë° í™˜ê²½ ì ìš© (on-device inference ìµœì í™”)

---

## ğŸ‘¥ Team â€œAloneâ€
| ì—­í•  | ì´ë¦„ |
|------|------|
| Team Leader / DL Engineer |  |
| Research & Evaluation |  |
| Research & Evaluation |  |
| Backend / System Integration |  |

---

## ğŸ§¾ License  
This project is for **academic research** purposes under the **Konkuk University Capstone Design (ì¡¸ì—…í”„ë¡œì íŠ¸)** program.  
For any citation or reuse, please credit:  
> *ALONE et al., â€œSpeaker diarization enhancement using denoising DL-modelâ€, Konkuk Univ., 2025.*
